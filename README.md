# USB Power Delivery (USB PD) Specification Parser

A sophisticated, production-ready system for parsing USB Power Delivery specification PDF documents and converting them into structured, machine-readable JSONL format. This system provides high-accuracy parsing with comprehensive validation and detailed reporting capabilities.

## üåü Key Features

- **üîç Multi-Library PDF Extraction**: Uses both `pdfplumber` and `PyMuPDF` for maximum reliability
- **üìã Advanced Table of Contents Parsing**: Multiple regex patterns with hierarchical structure detection
- **üìë Full Document Section Parsing**: Maps ToC entries to actual document content with boundary detection
- **üéØ High Accuracy**: Designed for >90% parsing accuracy with confidence scoring
- **üìä Comprehensive Validation**: Excel reports comparing ToC vs parsed sections with statistics
- **üîÑ Schema Validation**: JSON Schema validation for all output formats
- **üìà Detailed Analytics**: Content type detection, table/figure counting, and quality metrics
- **üèóÔ∏è Modular Architecture**: Easily extensible and maintainable codebase

## üìÅ Project Structure

```
usb_pd_parser/
‚îú‚îÄ‚îÄ main.py                     # Main orchestrator and CLI entry point
‚îú‚îÄ‚îÄ schemas/                    # JSON schemas for validation
‚îÇ   ‚îú‚îÄ‚îÄ toc_schema.json        # Table of Contents schema
‚îÇ   ‚îú‚îÄ‚îÄ document_schema.json   # Document sections schema
‚îÇ   ‚îî‚îÄ‚îÄ metadata_schema.json   # Metadata schema
‚îú‚îÄ‚îÄ parsers/                    # Core parsing modules
‚îÇ   ‚îú‚îÄ‚îÄ toc_parser.py          # Table of Contents parser
‚îÇ   ‚îî‚îÄ‚îÄ document_parser.py     # Document section parser
‚îú‚îÄ‚îÄ utils/                      # Utility modules
‚îÇ   ‚îú‚îÄ‚îÄ pdf_extractor.py       # PDF text extraction
‚îÇ   ‚îî‚îÄ‚îÄ jsonl_generator.py     # JSONL file generation
‚îú‚îÄ‚îÄ validators/                 # Validation and reporting
‚îÇ   ‚îî‚îÄ‚îÄ validation_report.py   # Excel validation reports
‚îî‚îÄ‚îÄ output/                     # Sample output files
    ‚îú‚îÄ‚îÄ usb_pd_toc.jsonl       # Sample ToC JSONL
    ‚îú‚îÄ‚îÄ usb_pd_spec.jsonl      # Sample document JSONL
    ‚îî‚îÄ‚îÄ usb_pd_metadata.jsonl  # Sample metadata JSONL
```

## üöÄ Installation

### Prerequisites

- Python 3.9+
- pip package manager

### Install Dependencies

```bash
# Install required Python packages
pip install pdfplumber PyMuPDF pandas openpyxl jsonschema regex tqdm

# Or install all at once
pip install --break-system-packages pdfplumber PyMuPDF pandas openpyxl jsonschema regex tqdm
```

### Dependencies Overview

- **pdfplumber**: Primary PDF text extraction library
- **PyMuPDF**: Fallback PDF library for enhanced reliability
- **pandas**: Data manipulation and Excel generation
- **openpyxl**: Excel file formatting and chart generation
- **jsonschema**: JSON Schema validation
- **regex**: Advanced regular expression support
- **tqdm**: Progress bars for long operations

## üìö Usage

### Command Line Interface

The system provides a comprehensive CLI for all operations:

```bash
# Basic usage - parse a PDF file
python -m usb_pd_parser.main parse document.pdf

# Parse with custom output directory
python -m usb_pd_parser.main parse document.pdf --output ./results

# Parse with custom document title
python -m usb_pd_parser.main parse document.pdf --title "USB PD Spec v3.1"

# Generate sample files for testing
python -m usb_pd_parser.main sample --output ./samples

# Enable verbose logging
python -m usb_pd_parser.main parse document.pdf --verbose
```

### Programmatic Usage

```python
from usb_pd_parser import USBPDSpecificationParser

# Initialize the parser
parser = USBPDSpecificationParser()

# Parse a PDF file
result = parser.parse_pdf(
    pdf_path="usb_pd_specification.pdf",
    output_dir="output",
    doc_title="USB PD Specification Rev 3.1"
)

# Check results
if result['success']:
    print(f"‚úÖ Parsing completed with {result['accuracy']:.1%} accuracy")
    print(f"üìÑ Found {result['parsing_results']['toc_entries_found']} ToC entries")
    print(f"üìë Parsed {result['parsing_results']['document_sections_parsed']} sections")
else:
    print(f"‚ùå Parsing failed: {result['error']}")

# Generate sample files for demonstration
sample_result = parser.generate_sample_files("sample_output")
```

## üìä Output Formats

### JSONL Files Generated

The system generates three main JSONL files:

#### 1. Table of Contents (`usb_pd_toc.jsonl`)

Each line contains a ToC entry with hierarchical information:

```json
{
  "doc_title": "USB Power Delivery Specification Rev 3.1",
  "section_id": "2.1.2",
  "title": "Power Delivery Contract Negotiation",
  "page": 53,
  "level": 3,
  "parent_id": "2.1",
  "full_path": "2.1.2 Power Delivery Contract Negotiation",
  "tags": ["contracts", "negotiation"]
}
```

#### 2. Document Sections (`usb_pd_spec.jsonl`)

Each line contains a full document section with content and metadata:

```json
{
  "doc_title": "USB Power Delivery Specification Rev 3.1",
  "section_id": "2.1.2",
  "title": "Power Delivery Contract Negotiation",
  "page_start": 53,
  "page_end": 55,
  "level": 3,
  "parent_id": "2.1",
  "full_path": "2.1.2 Power Delivery Contract Negotiation",
  "content": "This section covers the negotiation process...",
  "content_type": "text",
  "has_tables": false,
  "has_figures": true,
  "table_count": 0,
  "figure_count": 1,
  "word_count": 247,
  "tags": ["contracts", "negotiation"],
  "confidence_score": 0.92,
  "extraction_notes": []
}
```

#### 3. Document Metadata (`usb_pd_metadata.jsonl`)

Contains comprehensive parsing statistics and document information:

```json
{
  "doc_title": "USB Power Delivery Specification Rev 3.1",
  "doc_version": "3.1",
  "total_pages": 200,
  "parsing_timestamp": "2024-01-15T10:30:00",
  "parser_version": "1.0.0",
  "toc_statistics": {
    "total_sections": 45,
    "max_level": 4,
    "level_distribution": {"1": 5, "2": 15, "3": 20, "4": 5}
  },
  "content_statistics": {
    "total_sections_parsed": 43,
    "total_tables": 25,
    "total_figures": 18,
    "total_word_count": 50000,
    "content_type_distribution": {
      "text": 30, "table": 8, "figure": 3, "mixed": 2
    }
  },
  "parsing_quality": {
    "overall_confidence": 0.89,
    "toc_match_rate": 0.96,
    "extraction_errors": 2,
    "warnings": ["Minor formatting inconsistencies"]
  }
}
```

### Validation Report (`validation_report.xlsx`)

Comprehensive Excel report with multiple sheets:

- **Summary**: Overall statistics and quality metrics
- **Section_Comparison**: Detailed comparison of ToC vs parsed sections
- **Missing_Sections**: Sections found in ToC but missing from document
- **Extra_Sections**: Sections found in document but not in ToC
- **Page_Mismatches**: Page number inconsistencies
- **Quality_Issues**: Content quality problems and confidence issues
- **Statistics**: Level distribution and content type analysis

## üèóÔ∏è System Architecture

### Core Components

#### 1. PDF Extractor (`utils/pdf_extractor.py`)
- **Multi-library approach**: Primary pdfplumber with PyMuPDF fallback
- **Quality scoring**: Confidence scores for extracted text
- **Table/figure detection**: Automatic identification of visual elements
- **Page range extraction**: Efficient text extraction from page ranges
- **ToC page detection**: Automatic identification of Table of Contents pages

#### 2. ToC Parser (`parsers/toc_parser.py`)
- **Multiple regex patterns**: 7 different patterns for maximum coverage
- **Hierarchical structure detection**: Automatic parent-child relationship mapping
- **Content type classification**: Semantic tagging based on section titles
- **Validation system**: Structure consistency checking
- **Confidence scoring**: Quality assessment for each parsed entry

#### 3. Document Parser (`parsers/document_parser.py`)
- **Section boundary detection**: Intelligent start/end page determination
- **Content analysis**: Automatic classification of text, tables, figures, protocols
- **Metadata extraction**: Word counts, table/figure counts, content types
- **Quality assessment**: Confidence scoring and issue detection
- **Section mapping**: Links ToC entries to actual document content

#### 4. JSONL Generator (`utils/jsonl_generator.py`)
- **Schema validation**: All outputs validated against JSON schemas
- **Unicode support**: Proper handling of international characters
- **Batch processing**: Efficient generation of large files
- **Error handling**: Graceful handling of conversion issues
- **Sample generation**: Built-in sample data for testing

#### 5. Validation System (`validators/validation_report.py`)
- **Comprehensive comparison**: ToC vs document section analysis
- **Excel reporting**: Professional formatted reports with charts
- **Statistical analysis**: Level distribution, content type analysis
- **Quality metrics**: Confidence scores, match rates, error counts
- **Issue identification**: Missing sections, mismatches, quality problems

### Design Principles

1. **Robustness**: Multiple extraction methods with fallback mechanisms
2. **Accuracy**: Confidence scoring and validation at every step
3. **Modularity**: Loosely coupled components for easy maintenance
4. **Extensibility**: Easy to add new parsing patterns and content types
5. **Transparency**: Detailed logging and reporting for debugging
6. **Performance**: Efficient processing of large documents

## üîß Configuration and Customization

### Adding New Regex Patterns

To add new ToC parsing patterns, modify `parsers/toc_parser.py`:

```python
def _compile_patterns(self):
    # Add your custom pattern
    self.pattern_custom = re.compile(
        r'^(Custom Pattern Here)',
        re.MULTILINE | re.IGNORECASE
    )
    
    # Add to pattern list
    self.all_patterns.append(("custom", self.pattern_custom))
```

### Customizing Content Type Detection

Modify `parsers/document_parser.py` to add new content types:

```python
def _determine_content_type(self, has_tables, has_figures, ...):
    # Add custom content type logic
    if custom_condition:
        return "custom_type"
    # ... existing logic
```

### Schema Customization

Modify JSON schemas in the `schemas/` directory to change validation rules:

```json
{
  "properties": {
    "custom_field": {
      "type": "string",
      "description": "Custom field description"
    }
  }
}
```

## üìà Performance and Accuracy

### Benchmarks

- **Processing Speed**: ~2-5 pages per second depending on content complexity
- **Memory Usage**: ~50-100MB for typical 200-page documents
- **Accuracy Targets**: 
  - ToC extraction: >95% accuracy
  - Section mapping: >90% accuracy
  - Content extraction: >85% accuracy

### Quality Metrics

The system provides several quality indicators:

- **Confidence Scores**: 0.0-1.0 for each extracted element
- **Match Rates**: Percentage of ToC entries successfully mapped
- **Validation Status**: Excellent/Good/Fair/Poor overall assessment
- **Error Counts**: Detailed breakdown of extraction issues

### Optimization Tips

1. **PDF Quality**: Higher quality PDFs yield better results
2. **Text-based PDFs**: Avoid image-based PDFs when possible
3. **Consistent Formatting**: Documents with consistent ToC formatting parse better
4. **Memory**: For very large documents, consider processing in chunks

## üêõ Troubleshooting

### Common Issues

#### Low Confidence Scores
- **Cause**: Poor PDF quality or complex formatting
- **Solution**: Check PDF text extraction quality, consider OCR preprocessing

#### Missing ToC Entries
- **Cause**: Non-standard ToC formatting
- **Solution**: Add custom regex patterns or adjust existing ones

#### Page Mismatches
- **Cause**: Page numbering inconsistencies
- **Solution**: Manual verification, adjust page detection logic

#### Import Errors
- **Cause**: Missing dependencies
- **Solution**: Reinstall requirements: `pip install -r requirements.txt`

### Debug Mode

Enable verbose logging for detailed diagnostics:

```bash
python -m usb_pd_parser.main parse document.pdf --verbose
```

Check log files:
- `usb_pd_parser.log`: Detailed processing logs
- Validation warnings in Excel report

### Performance Issues

For large documents:
1. Monitor memory usage
2. Consider processing sections in batches
3. Use SSD storage for temporary files
4. Increase system memory if needed

## ü§ù Contributing

### Development Setup

```bash
# Clone the repository
git clone <repository-url>
cd usb_pd_parser

# Install development dependencies
pip install -r requirements.txt

# Run tests
python -m pytest tests/

# Generate sample files for testing
python -m usb_pd_parser.main sample
```

### Code Style

- Follow PEP 8 guidelines
- Use type hints for all functions
- Add comprehensive docstrings
- Include logging for major operations
- Write unit tests for new features

### Adding Features

1. Create feature branch: `git checkout -b feature/new-feature`
2. Implement with tests and documentation
3. Update JSON schemas if needed
4. Add validation rules
5. Update README with new functionality
6. Submit pull request

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## üôè Acknowledgments

- **USB Implementers Forum** for the USB PD specification
- **pdfplumber** and **PyMuPDF** communities for excellent PDF libraries
- **pandas** and **openpyxl** teams for data processing capabilities

## üìû Support

For technical questions or issues:

- Check the troubleshooting section above
- Review log files for detailed error information
- Open an issue with sample PDF and error logs
- Include system information and Python version

## üîÑ Version History

### v1.0.0 (Current)
- Initial release with comprehensive parsing system
- Multi-library PDF extraction
- Advanced ToC parsing with 7 regex patterns
- Full document section parsing
- Excel validation reports
- JSON Schema validation
- Sample file generation
- Command-line interface

### Planned Features
- OCR support for image-based PDFs
- Web interface for document upload
- API endpoints for integration
- Additional output formats (JSON, XML)
- Machine learning for pattern recognition
- Batch processing for multiple documents

---

**Built with ‚ù§Ô∏è for the USB PD community**

